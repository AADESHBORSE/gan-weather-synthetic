{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NhePLaLAUsW",
        "outputId": "ff294c51-79ff-4b96-9848-4101975acf38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch -y\n",
        "!pip cache purge  # Optional: to clear pip cache\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ==============================\n",
        "# 1. Upload dataset in Colab\n",
        "# ==============================\n",
        "from google.colab import files\n",
        "uploaded = files.upload()   # Choose weatherHistory.csv\n",
        "\n",
        "# ==============================\n",
        "# 2. Load dataset\n",
        "# ==============================\n",
        "df = pd.read_csv(\"weatherHistory.csv\")\n",
        "\n",
        "# Keep only numerical features\n",
        "numerical_features = [\n",
        "    \"Temperature (C)\", \"Apparent Temperature (C)\", \"Humidity\",\n",
        "    \"Wind Speed (km/h)\", \"Wind Bearing (degrees)\", \"Visibility (km)\",\n",
        "    \"Pressure (millibars)\"\n",
        "]\n",
        "\n",
        "df = df[numerical_features].dropna()  # Drop missing values\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# ==============================\n",
        "# 3. Normalize numerical features\n",
        "# ==============================\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "data_tensor = torch.tensor(data_scaled, dtype=torch.float32)\n",
        "dataset = TensorDataset(data_tensor)\n",
        "\n",
        "batch_size = 64\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ==============================\n",
        "# 4. Define GAN models\n",
        "# ==============================\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, output_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ==============================\n",
        "# 5. Setup\n",
        "# ==============================\n",
        "latent_dim = 100\n",
        "data_dim = len(numerical_features)\n",
        "num_epochs = 1000\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "G = Generator(latent_dim, data_dim).to(device)\n",
        "D = Discriminator(data_dim).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=0.0002)\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=0.0002)\n",
        "\n",
        "# ==============================\n",
        "# 6. Training Loop\n",
        "# ==============================\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_samples,) in enumerate(dataloader):\n",
        "        real_samples = real_samples.to(device)\n",
        "        batch_size_curr = real_samples.size(0)\n",
        "\n",
        "        # --- Train Discriminator ---\n",
        "        optimizer_D.zero_grad()\n",
        "        labels_real = torch.ones(batch_size_curr, 1).to(device)\n",
        "        output_real = D(real_samples)\n",
        "        loss_real = criterion(output_real, labels_real)\n",
        "\n",
        "        noise = torch.randn(batch_size_curr, latent_dim).to(device)\n",
        "        fake_samples = G(noise)\n",
        "        labels_fake = torch.zeros(batch_size_curr, 1).to(device)\n",
        "        output_fake = D(fake_samples.detach())\n",
        "        loss_fake = criterion(output_fake, labels_fake)\n",
        "\n",
        "        loss_D = (loss_real + loss_fake) / 2\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # --- Train Generator ---\n",
        "        optimizer_G.zero_grad()\n",
        "        output_fake_for_G = D(fake_samples)\n",
        "        loss_G = criterion(output_fake_for_G, labels_real)\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
        "        print(f\"[Epoch {epoch}/{num_epochs}] D_loss: {loss_D.item():.4f}, G_loss: {loss_G.item():.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 7. Generate synthetic data\n",
        "# ==============================\n",
        "G.eval()\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(5000, latent_dim).to(device)\n",
        "    synthetic_data = G(noise).cpu().numpy()\n",
        "\n",
        "# Inverse transform to original scale\n",
        "synthetic_data_original_scale = scaler.inverse_transform(synthetic_data)\n",
        "\n",
        "synthetic_df = pd.DataFrame(synthetic_data_original_scale, columns=numerical_features)\n",
        "print(\"\\nSynthetic data (first 10 rows):\")\n",
        "print(synthetic_df.head(10))\n",
        "\n",
        "# ==============================\n",
        "# 8. Save synthetic data to CSV\n",
        "# ==============================\n",
        "synthetic_df.to_csv(\"synthetic_weather.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download(\"synthetic_weather.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kaiw2Ay_AtKv",
        "outputId": "0997b2cf-bb36-48f1-be3b-c985ebce6746"
      },
      "execution_count": 3,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-826ab03a-51ca-4951-b97e-c082a8838700\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-826ab03a-51ca-4951-b97e-c082a8838700\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving weatherHistory.csv to weatherHistory (1).csv\n",
            "Dataset shape: (96453, 7)\n",
            "   Temperature (C)  Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n",
            "0         9.472222                  7.388889      0.89            14.1197   \n",
            "1         9.355556                  7.227778      0.86            14.2646   \n",
            "2         9.377778                  9.377778      0.89             3.9284   \n",
            "3         8.288889                  5.944444      0.83            14.1036   \n",
            "4         8.755556                  6.977778      0.83            11.0446   \n",
            "\n",
            "   Wind Bearing (degrees)  Visibility (km)  Pressure (millibars)  \n",
            "0                   251.0          15.8263               1015.13  \n",
            "1                   259.0          15.8263               1015.63  \n",
            "2                   204.0          14.9569               1015.94  \n",
            "3                   269.0          15.8263               1016.41  \n",
            "4                   259.0          15.8263               1016.51  \n",
            "Using device: cuda\n",
            "[Epoch 0/1000] D_loss: 0.6119, G_loss: 0.7319\n",
            "[Epoch 10/1000] D_loss: 0.8810, G_loss: 0.4955\n",
            "[Epoch 20/1000] D_loss: 0.6816, G_loss: 0.6024\n",
            "[Epoch 30/1000] D_loss: 0.7091, G_loss: 0.7164\n",
            "[Epoch 40/1000] D_loss: 0.7058, G_loss: 0.7094\n",
            "[Epoch 50/1000] D_loss: 0.7513, G_loss: 0.6794\n",
            "[Epoch 60/1000] D_loss: 0.6791, G_loss: 0.6929\n",
            "[Epoch 70/1000] D_loss: 0.7052, G_loss: 0.7471\n",
            "[Epoch 80/1000] D_loss: 0.6461, G_loss: 0.7763\n",
            "[Epoch 90/1000] D_loss: 0.7070, G_loss: 0.6807\n",
            "[Epoch 100/1000] D_loss: 0.7440, G_loss: 0.6043\n",
            "[Epoch 110/1000] D_loss: 0.6964, G_loss: 0.6718\n",
            "[Epoch 120/1000] D_loss: 0.7574, G_loss: 0.6903\n",
            "[Epoch 130/1000] D_loss: 0.6685, G_loss: 0.7016\n",
            "[Epoch 140/1000] D_loss: 0.6841, G_loss: 0.7039\n",
            "[Epoch 150/1000] D_loss: 0.7229, G_loss: 0.6880\n",
            "[Epoch 160/1000] D_loss: 0.7014, G_loss: 0.7000\n",
            "[Epoch 170/1000] D_loss: 0.7099, G_loss: 0.7166\n",
            "[Epoch 180/1000] D_loss: 0.6905, G_loss: 0.7250\n",
            "[Epoch 190/1000] D_loss: 0.7039, G_loss: 0.7007\n",
            "[Epoch 200/1000] D_loss: 0.7108, G_loss: 0.6603\n",
            "[Epoch 210/1000] D_loss: 0.6987, G_loss: 0.6900\n",
            "[Epoch 220/1000] D_loss: 0.7117, G_loss: 0.6737\n",
            "[Epoch 230/1000] D_loss: 0.6912, G_loss: 0.6752\n",
            "[Epoch 240/1000] D_loss: 0.7058, G_loss: 0.6861\n",
            "[Epoch 250/1000] D_loss: 0.6606, G_loss: 0.7306\n",
            "[Epoch 260/1000] D_loss: 0.7044, G_loss: 0.7059\n",
            "[Epoch 270/1000] D_loss: 0.7028, G_loss: 0.6798\n",
            "[Epoch 280/1000] D_loss: 0.6989, G_loss: 0.7258\n",
            "[Epoch 290/1000] D_loss: 0.6896, G_loss: 0.7005\n",
            "[Epoch 300/1000] D_loss: 0.6655, G_loss: 0.7707\n",
            "[Epoch 310/1000] D_loss: 0.7070, G_loss: 0.7136\n",
            "[Epoch 320/1000] D_loss: 0.6978, G_loss: 0.7087\n",
            "[Epoch 330/1000] D_loss: 0.6555, G_loss: 0.7553\n",
            "[Epoch 340/1000] D_loss: 0.7079, G_loss: 0.6886\n",
            "[Epoch 350/1000] D_loss: 0.7139, G_loss: 0.6700\n",
            "[Epoch 360/1000] D_loss: 0.6797, G_loss: 0.7494\n",
            "[Epoch 370/1000] D_loss: 0.6687, G_loss: 0.7314\n",
            "[Epoch 380/1000] D_loss: 0.7002, G_loss: 0.6746\n",
            "[Epoch 390/1000] D_loss: 0.6851, G_loss: 0.6894\n",
            "[Epoch 400/1000] D_loss: 0.7125, G_loss: 0.6697\n",
            "[Epoch 410/1000] D_loss: 0.6732, G_loss: 0.7083\n",
            "[Epoch 420/1000] D_loss: 0.7062, G_loss: 0.6879\n",
            "[Epoch 430/1000] D_loss: 0.6996, G_loss: 0.6859\n",
            "[Epoch 440/1000] D_loss: 0.6922, G_loss: 0.7135\n",
            "[Epoch 450/1000] D_loss: 0.6994, G_loss: 0.6996\n",
            "[Epoch 460/1000] D_loss: 0.7003, G_loss: 0.6857\n",
            "[Epoch 470/1000] D_loss: 0.6877, G_loss: 0.7053\n",
            "[Epoch 480/1000] D_loss: 0.7152, G_loss: 0.6756\n",
            "[Epoch 490/1000] D_loss: 0.6884, G_loss: 0.6966\n",
            "[Epoch 500/1000] D_loss: 0.6816, G_loss: 0.6990\n",
            "[Epoch 510/1000] D_loss: 0.6788, G_loss: 0.6930\n",
            "[Epoch 520/1000] D_loss: 0.6646, G_loss: 0.7205\n",
            "[Epoch 530/1000] D_loss: 0.6856, G_loss: 0.7012\n",
            "[Epoch 540/1000] D_loss: 0.7069, G_loss: 0.6528\n",
            "[Epoch 550/1000] D_loss: 0.6975, G_loss: 0.6973\n",
            "[Epoch 560/1000] D_loss: 0.6838, G_loss: 0.7170\n",
            "[Epoch 570/1000] D_loss: 0.7094, G_loss: 0.6888\n",
            "[Epoch 580/1000] D_loss: 0.6710, G_loss: 0.7606\n",
            "[Epoch 590/1000] D_loss: 0.7133, G_loss: 0.6775\n",
            "[Epoch 600/1000] D_loss: 0.7024, G_loss: 0.7034\n",
            "[Epoch 610/1000] D_loss: 0.7001, G_loss: 0.6939\n",
            "[Epoch 620/1000] D_loss: 0.7065, G_loss: 0.6899\n",
            "[Epoch 630/1000] D_loss: 0.7025, G_loss: 0.7115\n",
            "[Epoch 640/1000] D_loss: 0.6987, G_loss: 0.6893\n",
            "[Epoch 650/1000] D_loss: 0.6899, G_loss: 0.6841\n",
            "[Epoch 660/1000] D_loss: 0.6918, G_loss: 0.6604\n",
            "[Epoch 670/1000] D_loss: 0.6839, G_loss: 0.6639\n",
            "[Epoch 680/1000] D_loss: 0.6986, G_loss: 0.6992\n",
            "[Epoch 690/1000] D_loss: 0.6794, G_loss: 0.7219\n",
            "[Epoch 700/1000] D_loss: 0.7068, G_loss: 0.6778\n",
            "[Epoch 710/1000] D_loss: 0.6883, G_loss: 0.7142\n",
            "[Epoch 720/1000] D_loss: 0.6746, G_loss: 0.6863\n",
            "[Epoch 730/1000] D_loss: 0.6820, G_loss: 0.6983\n",
            "[Epoch 740/1000] D_loss: 0.6958, G_loss: 0.6758\n",
            "[Epoch 750/1000] D_loss: 0.6902, G_loss: 0.7126\n",
            "[Epoch 760/1000] D_loss: 0.6953, G_loss: 0.6983\n",
            "[Epoch 770/1000] D_loss: 0.7256, G_loss: 0.6568\n",
            "[Epoch 780/1000] D_loss: 0.6869, G_loss: 0.7099\n",
            "[Epoch 790/1000] D_loss: 0.6770, G_loss: 0.7254\n",
            "[Epoch 800/1000] D_loss: 0.6871, G_loss: 0.6967\n",
            "[Epoch 810/1000] D_loss: 0.7049, G_loss: 0.6875\n",
            "[Epoch 820/1000] D_loss: 0.6586, G_loss: 0.6964\n",
            "[Epoch 830/1000] D_loss: 0.7067, G_loss: 0.6441\n",
            "[Epoch 840/1000] D_loss: 0.6854, G_loss: 0.7033\n",
            "[Epoch 850/1000] D_loss: 0.6948, G_loss: 0.6878\n",
            "[Epoch 860/1000] D_loss: 0.6910, G_loss: 0.6952\n",
            "[Epoch 870/1000] D_loss: 0.6906, G_loss: 0.7030\n",
            "[Epoch 880/1000] D_loss: 0.7044, G_loss: 0.7070\n",
            "[Epoch 890/1000] D_loss: 0.6758, G_loss: 0.7203\n",
            "[Epoch 900/1000] D_loss: 0.6754, G_loss: 0.7090\n",
            "[Epoch 910/1000] D_loss: 0.6723, G_loss: 0.7036\n",
            "[Epoch 920/1000] D_loss: 0.7009, G_loss: 0.6972\n",
            "[Epoch 930/1000] D_loss: 0.6801, G_loss: 0.6917\n",
            "[Epoch 940/1000] D_loss: 0.6806, G_loss: 0.7133\n",
            "[Epoch 950/1000] D_loss: 0.6907, G_loss: 0.6930\n",
            "[Epoch 960/1000] D_loss: 0.6944, G_loss: 0.6874\n",
            "[Epoch 970/1000] D_loss: 0.6931, G_loss: 0.6864\n",
            "[Epoch 980/1000] D_loss: 0.6868, G_loss: 0.6881\n",
            "[Epoch 990/1000] D_loss: 0.6988, G_loss: 0.6722\n",
            "[Epoch 999/1000] D_loss: 0.6789, G_loss: 0.7133\n",
            "\n",
            "Synthetic data (first 10 rows):\n",
            "   Temperature (C)  Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n",
            "0         7.974491                  8.418450  0.984296           7.783060   \n",
            "1        -1.479392                 -4.118075  0.795761           9.748281   \n",
            "2        -1.139553                  0.282827  0.972260           1.612362   \n",
            "3         5.256083                  4.360704  0.800679          10.419284   \n",
            "4         3.717910                  1.872987  0.617130          14.169557   \n",
            "5         9.862153                  8.564171  0.761010          16.195667   \n",
            "6        17.262667                 18.441504  0.857677           2.678101   \n",
            "7        11.422050                 11.657316  0.724011           7.739052   \n",
            "8        11.835603                 11.693926  0.707453          21.569365   \n",
            "9        18.744732                 19.562553  0.829817           8.163821   \n",
            "\n",
            "   Wind Bearing (degrees)  Visibility (km)  Pressure (millibars)  \n",
            "0              162.390823        11.099949           1011.087708  \n",
            "1              133.998245         9.550829           1022.541748  \n",
            "2              235.247253         1.031597           1018.396057  \n",
            "3              169.728256        11.038795           1024.127319  \n",
            "4               54.858246        16.086197           1029.453979  \n",
            "5              260.236023         9.794634           1009.171814  \n",
            "6               93.198318        12.249862           1008.523682  \n",
            "7              312.009338        16.096455           1023.204346  \n",
            "8               13.952696         9.381042           1009.699402  \n",
            "9              333.396515        12.052470            993.986755  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_da78b444-8f7f-4fbc-838e-cc4b132d4627\", \"synthetic_weather.csv\", 346644)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mea35KsSIPzC",
        "outputId": "4cdd894c-bc6f-4d1e-8556-cee2bde06b5e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save synthetic data to a CSV file\n",
        "synthetic_df.to_csv(\"synthetic_weather_data.csv\", index=False)\n",
        "\n",
        "# Download the file (for Colab)\n",
        "from google.colab import files\n",
        "files.download(\"synthetic_weather_data.csv\")"
      ],
      "metadata": {
        "id": "JclVYNEeBIjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "rmse_scores = {}\n",
        "for col in numerical_features:\n",
        "    mse = mean_squared_error(real_numerical[col], synthetic_numerical[col])\n",
        "    rmse = np.sqrt(mse)\n",
        "    rmse_scores[col] = rmse\n",
        "\n",
        "# Display\n",
        "print(\"沐 RMSE per feature:\")\n",
        "for k, v in rmse_scores.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# Optional: overall mean RMSE\n",
        "mean_rmse = np.mean(list(rmse_scores.values()))\n",
        "print(f\"\\n笞｡ Mean RMSE across all numerical features: {mean_rmse:.4f}\")"
      ],
      "metadata": {
        "id": "g28Y62aFBNI2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}